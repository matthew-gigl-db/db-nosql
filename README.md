# db-nosql
Databricks and NoSQL

## This project is under development...

Databricks is already known as a great ETL Tool, but did you know it can also be used to serve API requests just like a NoSQL database as well?  In this demo we'll do the following:  

* Create or assign a catalog, schema, and volume to use with some synthetic patient data generated by Synthetic Health's Synthea package: [https://github.com/synthetichealth/synthea](https://github.com/synthetichealth/synthea)
* Generate synthetic patient records that we'll be able to stream into a medallion architecture using Delta Live Tables.  
* Create API calls to the Databricks SQL Warehouses to retrieve the data in JSON format.  
* Run a simulation to get the distribution of API response times from the Databricks SQL Warehouses. 

Bonuses:  
* Demonstrate reading and writing data from a CosmosDB using Spark Structured Streaming and the Spark-Cosmos connector from Microsoft.  [https://github.com/Azure/azure-sdk-for-java/tree/main/sdk/cosmos/azure-cosmos-spark_3-5_2-12](https://github.com/Azure/azure-sdk-for-java/tree/main/sdk/cosmos/azure-cosmos-spark_3-5_2-12)
* Compare the results of querying from CosmosDB vs directly from the lakehouse.  

***

Dependencies: 
* These notebooks and required jar files were intended to run on DBR 14.3 LTS.  The advanced options of the cluster must be set to include the following environment variable: `JNAME=zulu17-ca-amd64`.  This ensures that the cluster uses Java version 17 instead of the default Java version 8.  Either Java version 11 or version 17 is required to run the Synthea Patient Generator.  

<img src="https://github.com/matthew-gigl-db/db-nosql/blob/main/images/Java17EnvVariable.png?raw=true">

***







